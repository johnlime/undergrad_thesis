\chapter{Approach}
% def of pigeon model
  We define a simplified 2-dimensional model of pigeons based on incremental modeling. The pigeon model consists of 3 joints connecting one body representing the head, 2 bodies representing the neck, and one body representing the torso. The model's physics, mainly the collision and gravity, is simulated in a 2 dimensional physics engine. The torso's orientation and y-position is fixed while its x-position is incremented by a constant value. This represents forward locomotion at a constant speed.

  Additionally, we build control systems for the model using reinforcement learning. By using reinforcement learning, we can train the controller to maximize reward functions that represent hypotheses or manually-defined trajectories for the bodies in the model to follow.

  As the baseline for the model's control system, we attempt to recreate the head-bob movement by setting a target position for the head's position to match every timestep. The target position is first defined at a set location in front of the pigeon model $T$ relative to the position of its torso. The target then acts as a static position in the global coordinate for the head to follow. If the distance between the target position and the torso's position goes below a set threshold value, the target is repositioned at the same location $T$ relative to the torso's position.

% Hypothesis Testing
  We compare the trajectories of the bodies in the baseline control system to those generated by the control system that represents preliminary hypotheses.

  %% description below should assume that we already know the angle of objects within retina
  % Preliminary hypotheses for the functionalities of head-bobbing behavior can be depicted using two reward functions, each depicting head stabilization and motion parallax generation.

  % Hold phase: Head stabilization
    % retinal velocities of objects should be minimized
    % static objects should be stabilized into one location in the retina (; moving objects' velocities should be represented as relative velocities to those of global static objects).
    % reward function equation
    % \begin{equation}
    %   r_t = - \sum_i^n |\dot \theta_i|
    % \end{equation}
    % where $n$ is the number of objects in the environment and $\dot \theta$ is the angular velocity of each object.

  % Thrust phase: Maximizing motion parallax
    % sum of all velocities of objects should be maximized
  % how would optimization algorithms solve this tradeoff?


% Experiment details
\chapter{Experiments}
% objects placed on the surrounding environment of the pigeon

% SAC a type of reinforcement learning model
  % epochs
  % timesteps
% why we didn't use PPO
  % we tested it, and SAC seemed to have a more stable learning curve; thought that it would be more reliable
  % SAC represents the exploration of new trajectories of actions more; exploration of better execution seen in biological organisms' behaviors
