\chapter{Discussion}
% "results indicate that..."
  Examining the trajectories of each of the pigeon models' heads as seen in \ref{fig:head_bs_0}, the resulting behavior exhibited by the pigeon model with a fixed body, whose deep reinforcement learning controller was trained on $r_{fifty\_fifty}$, indicate that the combination of visual stabilization and motion parallax are sufficient to generate a behavior that fixes the position of the head, resembling the hold phase in pigeons.

  On the other hand, the resulting behavior exhibited by the pigeon model with body speed 1, whose deep reinforcement learning controller was trained on the same reward function as seen in Figures \ref{fig:head_bs_1_all_trimmed} and \ref{fig:head_bs_1_closest_trimmed}, indicate that the 2 functionalities are insufficient to produce head-bobbing behaviors in moving bodies during forward locomotion, as he pigeon model did not need to periodically thrust its head forward to maximize Davies' equation depicting motion parallax between objects.

  Such results indicate that visual stabilization with retinal cells capable of detecting movement in all directions is enough to maximize the sum of external objects' angular velocities within the retina.
    Examining Davies' equation \ref{equ:davies_motion_parallax}, it can be hypothesized that reinforcement learning controllers trained on reward function that reflect such function would only reproduce head-bobbing behaviors when all objects within the retina are globally static, since the equation does not account for the objects' velocities.
    Since the external objects in our experiment had objects moving forwards and backwards, such may have automatically increased the reward function depicting Davies' equation of motion parallax per timestep.


% fifty_fifty
  % one possible argument against our claim can be pointed to our decision to weigh $r_{head\_stabilize}$ and $r_{motion\_parallax}$ for the rewards and eventually the return.
  % change weights?
  % but the max return for $r_{head\_stabilize}$ is 0, and yet they're still producing high returns
  % factors other than fifty/fifty weight assignment

% may need a state machine-like mechanism for replication of head-bob
  % composed of the "hold phase" state and the "thrust phase" state
% hierarchical control system
  % hierarchical reinforcement learning should be used for modeling the control system with this hypothesis
% indicates that a hierarchical control system is embedded in pigeons' neurology.
% pattern generating module or functionality, such as central pattern generators seen in the spinal cortex

% head goes downwards during forward locomotion
% lack of muscular strain penalty?

% needs higher details, such as an addition of muscular physics, and progression in incremental modeling
% muscular simulation and their placements upon the skeletal model may lead to more stabilization (cite Geijtenbeek)
