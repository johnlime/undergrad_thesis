\chapter{Background: Reinforcement Learning}
% \section{Reinforcement Learning}
% rl feedback loop and reward system
  Reinforcement learning is a type of control system that attempts to execute tasks described by manually set cost functions by minimizing them using optimization algorithms or learning algorithms. In the case of deep reinforcement learning, the controller is modeled using deep neural networks and the cost function is minimized using gradient descent algorithms.

  Reinforcement learning divides control systems into an agent and an environment. The agent acts the controller of the system that inspects its environment's state and sends output signals, or actions, that affect the environment. This mutual interactions creates a feedback loop between the two modules.

  In the context of a pigeon tasked to move forward, the pigeon's brain and its nervous system connected to each limb act as the agent, and its surroundings, such as the ground and arbitrary objects on it, act as the environment. The environment outputs a state, such as the global position of the pigeon, which is used as the input for the agent. Using the provided state, the agent calculates and outputs an action, such as the torque of each joint in the pigeon's body. The action alters the state of the environment, and the environment outputs a new state and a reward. The reward describes how well the pigeon was able to execute its task, such as the current position of the pigeon relative to its previous timestep. The agent is updated to output sequences of actions that maximizes the cumulative reward, or return. The return can be interpreted as the inverted or negated cost function.

% using reward as a cost function / constraint / task def
  Deep reinforcement learning algorithms can train deep neural network controllers to maximize cumulative sums of arbitrarily-defined reward functions, as long as they are achievable within the given environment. Therefore, in application to biology, we can encode constraints and definitions of tasks, such as behaviors produced by biological organisms, into reward functions, train control systems to follow such constraints and tasks, and generate behaviors accordingly, while abiding by the laws of physics.

% drl examples
  Notable deep reinforcement learning algorithms include proximal policy optimization (PPO) \cite{schulman2017proximal} and soft actor critic (SAC) \cite{haarnoja2018soft}.
  PPO is used as baseline for many reinforcement learning experiments such as building agents to play games, particularly Pommerman \cite{gao2019skynet}, controlling automated vehicles \cite{guan2020centralized}, and controlling unmanned aircrafts \cite{bohn2019deep}.
  On the other hand, SAC has been shown to perform better than PPO in benchmark tests and has been applied to biology-inspired robotics, particularly quadrupedal robotic control \cite{haarnoja2018softappli}.
